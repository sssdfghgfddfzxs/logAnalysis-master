# AI Service Configuration (集成LLM分析功能)
AI_SERVICE_PORT=50051
AI_SERVICE_HOST=0.0.0.0

# Model Configuration
MODEL_PATH=./models
CONTAMINATION_RATE=0.1

# Anomaly Detection Method
# Set to 'true' to use LLM-based detection, 'false' for traditional ML
USE_LLM_DETECTION=true

# LLM Configuration
SILICONFLOW_API_TOKEN=your_siliconflow_api_token_here
SILICONFLOW_API_URL=https://api.siliconflow.cn/v1/chat/completions
SILICONFLOW_MODEL=Qwen/QwQ-32B

# Logging Configuration
LOG_LEVEL=INFO