import os
import json
import logging
import requests
import time
from typing import List, Dict, Any, Optional
from datetime import datetime

class LLMAnalyzer:
    """å¤§æ¨¡å‹åˆ†æå™¨ - ä½¿ç”¨SiliconFlow APIè¿›è¡Œæ·±åº¦æ—¥å¿—åˆ†æ"""
    
    def __init__(self):
        self.api_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.api_token = os.getenv('SILICONFLOW_API_TOKEN')
        self.model = "Qwen/QwQ-32B"
        
        if not self.api_token:
            logging.warning("SILICONFLOW_API_TOKEN not found in environment variables")
    
    def analyze_logs_batch(self, logs: List[Dict[str, Any]], anomaly_results: Dict[str, List] = None) -> Dict[str, Any]:
        """æ‰¹é‡åˆ†ææ—¥å¿—ï¼Œä¸€æ¬¡æ€§å®Œæˆå¼‚å¸¸æ£€æµ‹å’Œæ ¹å› åˆ†æ"""
        if not self.api_token:
            logging.info("LLM analysis skipped: API token not configured")
            return self._get_default_comprehensive_analysis(logs)
        
        try:
            # æ„å»ºç»¼åˆåˆ†ææç¤ºè¯
            prompt = self._build_comprehensive_analysis_prompt(logs)
            
            # è°ƒç”¨å¤§æ¨¡å‹API
            response = self._call_llm_api(prompt)
            
            if response:
                return self._parse_comprehensive_response(response, logs)
            else:
                return self._get_default_comprehensive_analysis(logs)
                
        except Exception as e:
            logging.warning(f"LLM comprehensive analysis failed, using fallback: {str(e)}")
            return self._get_default_comprehensive_analysis(logs)
    
    def analyze_single_log(self, log: Dict[str, Any], context_logs: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ—¥å¿—æ¡ç›®"""
        if not self.api_token:
            return self._get_default_single_analysis()
        
        try:
            prompt = self._build_single_log_prompt(log, context_logs)
            response = self._call_llm_api(prompt)
            
            if response:
                return self._parse_single_log_response(response)
            else:
                return self._get_default_single_analysis()
                
        except Exception as e:
            logging.warning(f"Single log LLM analysis failed: {str(e)}")
            return self._get_default_single_analysis()
    
    def _prepare_analysis_data(self, logs: List[Dict[str, Any]], anomaly_results: Dict[str, List]) -> Dict[str, Any]:
        """å‡†å¤‡åˆ†ææ•°æ®"""
        anomalies = []
        normal_logs = []
        error_logs = []
        
        for i, log in enumerate(logs):
            log_data = {
                'timestamp': log.get('timestamp', ''),
                'level': log.get('level', ''),
                'message': log.get('message', ''),
                'source': log.get('source', ''),
                'anomaly_score': anomaly_results['scores'][i] if i < len(anomaly_results['scores']) else 0
            }
            
            if anomaly_results['is_anomaly'][i] if i < len(anomaly_results['is_anomaly']) else False:
                anomalies.append(log_data)
            elif log.get('level', '').upper() in ['ERROR', 'FATAL', 'CRITICAL']:
                error_logs.append(log_data)
            else:
                normal_logs.append(log_data)
        
        return {
            'total_logs': len(logs),
            'anomalies': anomalies[:10],  # é™åˆ¶æ•°é‡é¿å…tokenè¿‡å¤š
            'error_logs': error_logs[:10],
            'normal_logs': normal_logs[:5],
            'anomaly_rate': len(anomalies) / len(logs) if logs else 0
        }
    
    def _build_analysis_prompt(self, data: Dict[str, Any]) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥å¿—åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ—¥å¿—æ•°æ®å¹¶æä¾›æ·±åº¦æ´å¯Ÿã€‚

## æ—¥å¿—ç»Ÿè®¡
- æ€»æ—¥å¿—æ•°: {data['total_logs']}
- å¼‚å¸¸æ—¥å¿—æ•°: {len(data['anomalies'])}
- é”™è¯¯æ—¥å¿—æ•°: {len(data['error_logs'])}
- å¼‚å¸¸ç‡: {data['anomaly_rate']:.2%}

## å¼‚å¸¸æ—¥å¿—æ ·æœ¬
{json.dumps(data['anomalies'], ensure_ascii=False, indent=2)}

## é”™è¯¯æ—¥å¿—æ ·æœ¬
{json.dumps(data['error_logs'], ensure_ascii=False, indent=2)}

## æ­£å¸¸æ—¥å¿—æ ·æœ¬
{json.dumps(data['normal_logs'], ensure_ascii=False, indent=2)}

è¯·æä¾›ä»¥ä¸‹åˆ†æç»“æœï¼ˆè¯·ç”¨JSONæ ¼å¼å›å¤ï¼‰ï¼š
{{
    "summary": "æ•´ä½“åˆ†ææ‘˜è¦",
    "key_findings": ["å…³é”®å‘ç°1", "å…³é”®å‘ç°2", "å…³é”®å‘ç°3"],
    "risk_assessment": {{
        "level": "LOW/MEDIUM/HIGH",
        "description": "é£é™©è¯„ä¼°æè¿°"
    }},
    "patterns": ["å‘ç°çš„æ¨¡å¼1", "å‘ç°çš„æ¨¡å¼2"],
    "recommendations": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"],
    "potential_issues": ["æ½œåœ¨é—®é¢˜1", "æ½œåœ¨é—®é¢˜2"],
    "trend_analysis": "è¶‹åŠ¿åˆ†æ"
}}"""
        
        return prompt
    
    def _build_single_log_prompt(self, log: Dict[str, Any], context_logs: List[Dict[str, Any]] = None) -> str:
        """æ„å»ºå•ä¸ªæ—¥å¿—åˆ†ææç¤ºè¯"""
        context_info = ""
        if context_logs:
            context_info = f"\n## ä¸Šä¸‹æ–‡æ—¥å¿—\n{json.dumps(context_logs[-5:], ensure_ascii=False, indent=2)}"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥å¿—åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å•ä¸ªæ—¥å¿—æ¡ç›®ï¼š

## ç›®æ ‡æ—¥å¿—
{json.dumps(log, ensure_ascii=False, indent=2)}
{context_info}

è¯·æä¾›ä»¥ä¸‹åˆ†æç»“æœï¼ˆè¯·ç”¨JSONæ ¼å¼å›å¤ï¼‰ï¼š
{{
    "severity": "LOW/MEDIUM/HIGH/CRITICAL",
    "category": "æ—¥å¿—ç±»åˆ«ï¼ˆå¦‚ï¼šç³»ç»Ÿé”™è¯¯ã€ä¸šåŠ¡å¼‚å¸¸ã€æ€§èƒ½é—®é¢˜ç­‰ï¼‰",
    "root_cause": "å¯èƒ½çš„æ ¹æœ¬åŸå› ",
    "impact": "æ½œåœ¨å½±å“",
    "immediate_actions": ["ç«‹å³è¡ŒåŠ¨å»ºè®®1", "ç«‹å³è¡ŒåŠ¨å»ºè®®2"],
    "investigation_steps": ["è°ƒæŸ¥æ­¥éª¤1", "è°ƒæŸ¥æ­¥éª¤2"],
    "related_components": ["ç›¸å…³ç»„ä»¶1", "ç›¸å…³ç»„ä»¶2"]
}}"""
        
        return prompt
    
    def _call_llm_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨å¤§æ¨¡å‹API"""
        try:
            logging.info(f"Starting LLM API call to {self.api_url}")
            logging.debug(f"Using model: {self.model}")
            logging.debug(f"Prompt length: {len(prompt)} characters")
            
            headers = {
                'Authorization': f'Bearer {self.api_token[:10]}...',  # åªæ˜¾ç¤ºtokenå‰10ä½ç”¨äºè°ƒè¯•
                'Content-Type': 'application/json'
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "stream": False,
                "temperature": 0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜åˆ†æçš„ä¸€è‡´æ€§
                "max_tokens": 2000
            }
            
            logging.info("Sending request to LLM API...")
            start_time = time.time()
            
            response = requests.post(
                self.api_url,
                headers={
                    'Authorization': f'Bearer {self.api_token}',
                    'Content-Type': 'application/json'
                },
                json=data,
                timeout=120
            )
            
            elapsed_time = time.time() - start_time
            logging.info(f"LLM API response received in {elapsed_time:.2f} seconds")
            logging.info(f"Response status code: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                logging.info(f"LLM API call successful, response length: {len(content)} characters")
                logging.debug(f"Response preview: {content[:200]}...")
                return content
            else:
                logging.error(f"LLM API error: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.Timeout as e:
            logging.error(f"LLM API timeout after 120 seconds: {str(e)}")
            logging.error("Consider increasing timeout or checking network connectivity")
            return None
        except requests.exceptions.ConnectionError as e:
            logging.error(f"LLM API connection error: {str(e)}")
            logging.error("Check if the API endpoint is accessible")
            return None
        except requests.exceptions.RequestException as e:
            logging.error(f"LLM API request error: {str(e)}")
            return None
        except Exception as e:
            logging.error(f"Unexpected error calling LLM API: {str(e)}")
            logging.error(f"Error type: {type(e).__name__}")
            return None
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """è§£æå¤§æ¨¡å‹å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx:end_idx]
                return json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›æ–‡æœ¬åˆ†æ
                return {
                    "summary": response[:500],
                    "key_findings": ["LLMåˆ†æç»“æœéœ€è¦äººå·¥è§£è¯»"],
                    "risk_assessment": {"level": "MEDIUM", "description": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ"},
                    "patterns": [],
                    "recommendations": ["è¯·æŸ¥çœ‹å®Œæ•´çš„LLMåˆ†æç»“æœ"],
                    "potential_issues": [],
                    "trend_analysis": "åˆ†æç»“æœæ ¼å¼å¼‚å¸¸"
                }
                
        except json.JSONDecodeError as e:
            logging.error(f"Error parsing LLM response: {str(e)}")
            return self._get_default_analysis()
    
    def _parse_single_log_response(self, response: str) -> Dict[str, Any]:
        """è§£æå•ä¸ªæ—¥å¿—çš„å¤§æ¨¡å‹å“åº”"""
        try:
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx:end_idx]
                return json.loads(json_str)
            else:
                return {
                    "severity": "MEDIUM",
                    "category": "æœªåˆ†ç±»",
                    "root_cause": response[:200],
                    "impact": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
                    "immediate_actions": ["æŸ¥çœ‹å®Œæ•´åˆ†æç»“æœ"],
                    "investigation_steps": ["äººå·¥å®¡æŸ¥"],
                    "related_components": []
                }
                
        except json.JSONDecodeError as e:
            logging.error(f"Error parsing single log LLM response: {str(e)}")
            return self._get_default_single_analysis()
    
    def _get_default_analysis(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†æç»“æœ"""
        return {
            "summary": "ä½¿ç”¨ä¼ ç»ŸAIåˆ†ææ–¹æ³•",
            "key_findings": ["åŸºäºè§„åˆ™çš„å¼‚å¸¸æ£€æµ‹"],
            "risk_assessment": {"level": "MEDIUM", "description": "éœ€è¦äººå·¥ç¡®è®¤"},
            "patterns": [],
            "recommendations": ["æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"],
            "potential_issues": [],
            "trend_analysis": "ä¼ ç»Ÿåˆ†ææ¨¡å¼"
        }
    
    def _get_default_single_analysis(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤å•ä¸ªæ—¥å¿—åˆ†æç»“æœ"""
        return {
            "severity": "MEDIUM",
            "category": "ç³»ç»Ÿæ—¥å¿—",
            "root_cause": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
            "impact": "å¯èƒ½å½±å“ç³»ç»Ÿç¨³å®šæ€§",
            "immediate_actions": ["æ£€æŸ¥ç›¸å…³æœåŠ¡çŠ¶æ€", "æŸ¥çœ‹ç³»ç»Ÿèµ„æº"],
            "investigation_steps": ["åˆ†ææ—¥å¿—ä¸Šä¸‹æ–‡", "æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡"],
            "related_components": []
        }
    def _build_comprehensive_analysis_prompt(self, logs: List[Dict[str, Any]]) -> str:
        """æ„å»ºä¼˜åŒ–çš„ç»¼åˆåˆ†ææç¤ºè¯ï¼Œæå‡åˆ†æå‡†ç¡®æ€§"""
        logs_data = []
        for i, log in enumerate(logs[:15]):  # é€‚å½“å‡å°‘æ•°é‡ï¼Œæå‡åˆ†æè´¨é‡
            logs_data.append({
                'index': i,
                'timestamp': log.get('timestamp', ''),
                'level': log.get('level', ''),
                'message': log.get('message', ''),
                'source': log.get('source', '')
            })
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç³»ç»Ÿè¿ç»´å’Œæ—¥å¿—åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„æ•…éšœè¯Šæ–­ç»éªŒã€‚è¯·å¯¹ä»¥ä¸‹æ—¥å¿—è¿›è¡Œä¸“ä¸šçš„ç»¼åˆåˆ†æã€‚

## æ—¥å¿—æ•°æ®
{json.dumps(logs_data, ensure_ascii=False, indent=2)}

## åˆ†æè¦æ±‚
è¯·ä¸ºæ¯ä¸ªæ—¥å¿—æä¾›ç²¾å‡†çš„åˆ†æï¼Œå¹¶ç»™å‡ºæ•´ä½“è¯„ä¼°ã€‚é‡ç‚¹å…³æ³¨ï¼š
1. **å¼‚å¸¸è¯†åˆ«**ï¼šåŸºäºæ—¥å¿—å†…å®¹ã€çº§åˆ«ã€é”™è¯¯æ¨¡å¼è¿›è¡Œå‡†ç¡®åˆ¤æ–­
2. **æ ¹å› åˆ†æ**ï¼šæ·±å…¥åˆ†æå¯èƒ½çš„æŠ€æœ¯åŸå› å’Œä¸šåŠ¡å½±å“
3. **è§£å†³å»ºè®®**ï¼šæä¾›å…·ä½“å¯æ‰§è¡Œçš„ä¿®å¤æ­¥éª¤
4. **é£é™©è¯„ä¼°**ï¼šè¯„ä¼°å¯¹ç³»ç»Ÿç¨³å®šæ€§å’Œä¸šåŠ¡çš„å½±å“ç¨‹åº¦

## å¼‚å¸¸åˆ¤æ–­æ ‡å‡†
- **é«˜é£é™©å¼‚å¸¸**ï¼šFATAL/CRITICALçº§åˆ«ï¼Œç³»ç»Ÿå´©æºƒã€å†…å­˜æº¢å‡ºã€è¿æ¥æ‹’ç»ã€å®‰å…¨æ”»å‡»
- **ä¸­é£é™©å¼‚å¸¸**ï¼šERRORçº§åˆ«ï¼Œä¸šåŠ¡é€»è¾‘é”™è¯¯ã€è¶…æ—¶ã€è®¤è¯å¤±è´¥ã€èµ„æºä¸è¶³
- **ä½é£é™©å¼‚å¸¸**ï¼šWARNçº§åˆ«ï¼Œæ€§èƒ½ä¸‹é™ã€é…ç½®é—®é¢˜ã€é‡è¯•æˆåŠŸ
- **æ­£å¸¸æ—¥å¿—**ï¼šINFO/DEBUGçº§åˆ«ï¼Œæ— é”™è¯¯å…³é”®è¯çš„å¸¸è§„æ“ä½œæ—¥å¿—

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š

{{
    "individual_results": [
        {{
            "index": 0,
            "is_anomaly": true/false,
            "anomaly_score": 0.0-1.0,
            "severity": "CRITICAL/HIGH/MEDIUM/LOW",
            "category": "ç³»ç»Ÿé”™è¯¯/ä¸šåŠ¡å¼‚å¸¸/æ€§èƒ½é—®é¢˜/å®‰å…¨é—®é¢˜/é…ç½®é—®é¢˜/ç½‘ç»œé—®é¢˜",
            "root_causes": ["å…·ä½“çš„æŠ€æœ¯åŸå› 1", "å¯èƒ½çš„ä¸šåŠ¡åŸå› 2"],
            "recommendations": ["ç«‹å³æ‰§è¡Œçš„ä¿®å¤æ­¥éª¤1", "é¢„é˜²æªæ–½2"],
            "impact": "å¯¹ç³»ç»Ÿå’Œä¸šåŠ¡çš„å…·ä½“å½±å“æè¿°"
        }}
    ],
    "summary": "æ•´ä½“ç³»ç»Ÿå¥åº·çŠ¶å†µå’Œä¸»è¦é—®é¢˜æ€»ç»“",
    "key_findings": ["æœ€é‡è¦çš„å‘ç°1", "å…³é”®é—®é¢˜2", "è¶‹åŠ¿è§‚å¯Ÿ3"],
    "risk_assessment": {{
        "level": "CRITICAL/HIGH/MEDIUM/LOW",
        "description": "å½“å‰ç³»ç»Ÿé£é™©çŠ¶å†µçš„ä¸“ä¸šè¯„ä¼°",
        "urgent_actions": ["éœ€è¦ç«‹å³å¤„ç†çš„é—®é¢˜1", "ç´§æ€¥æªæ–½2"]
    }},
    "recommendations": ["ç³»ç»Ÿçº§ä¼˜åŒ–å»ºè®®1", "ç›‘æ§æ”¹è¿›å»ºè®®2", "é¢„é˜²æªæ–½3"],
    "anomaly_count": å¼‚å¸¸æ—¥å¿—æ•°é‡,
    "total_count": æ€»æ—¥å¿—æ•°é‡,
    "trend_analysis": "åŸºäºæ—¥å¿—æ¨¡å¼çš„è¶‹åŠ¿åˆ†æå’Œé¢„æµ‹"
}}

è¯·ç¡®ä¿åˆ†æç»“æœä¸“ä¸šã€å‡†ç¡®ã€å¯æ‰§è¡Œã€‚"""
        
        return prompt

    def _parse_comprehensive_response(self, response: str, logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è§£æç»¼åˆåˆ†æå“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx:end_idx]
                result = json.loads(json_str)
            else:
                raise json.JSONDecodeError("No JSON found", response, 0)
            
            # ç¡®ä¿individual_resultsçš„æ•°é‡ä¸è¾“å…¥æ—¥å¿—åŒ¹é…
            individual_results = result.get('individual_results', [])
            while len(individual_results) < len(logs):
                # ä¸ºç¼ºå¤±çš„æ—¥å¿—æ·»åŠ é»˜è®¤åˆ†æç»“æœ
                log = logs[len(individual_results)]
                default_result = {
                    "index": len(individual_results),
                    "is_anomaly": log.get('level', '').upper() in ['ERROR', 'FATAL', 'CRITICAL'],
                    "anomaly_score": 0.8 if log.get('level', '').upper() in ['ERROR', 'FATAL', 'CRITICAL'] else 0.1,
                    "root_causes": [f"ğŸ¤– {log.get('level', 'INFO')}çº§åˆ«æ—¥å¿—"],
                    "recommendations": ["ğŸ” å»ºè®®æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"],
                    "severity": "HIGH" if log.get('level', '').upper() in ['ERROR', 'FATAL', 'CRITICAL'] else "LOW"
                }
                individual_results.append(default_result)
            
            result['individual_results'] = individual_results
            return result
            
        except json.JSONDecodeError as e:
            logging.warning(f"Failed to parse LLM response as JSON: {e}")
            return self._get_default_comprehensive_analysis(logs)
        except Exception as e:
            logging.warning(f"Error parsing comprehensive response: {e}")
            return self._get_default_comprehensive_analysis(logs)

    def _get_default_comprehensive_analysis(self, logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„ç»¼åˆåˆ†æç»“æœ"""
        individual_results = []
        anomaly_count = 0
        
        for i, log in enumerate(logs):
            level = log.get('level', '').upper()
            is_anomaly = level in ['ERROR', 'FATAL', 'CRITICAL']
            if is_anomaly:
                anomaly_count += 1
            
            individual_results.append({
                "index": i,
                "is_anomaly": is_anomaly,
                "anomaly_score": 0.8 if is_anomaly else 0.1,
                "root_causes": [f"ğŸ“Š ä¼ ç»Ÿåˆ†æ: {level}çº§åˆ«æ—¥å¿—"],
                "recommendations": ["ğŸ” å»ºè®®è¿›ä¸€æ­¥åˆ†æ"] if is_anomaly else ["âœ… æ—¥å¿—æ­£å¸¸"],
                "severity": "HIGH" if is_anomaly else "LOW"
            })
        
        return {
            "individual_results": individual_results,
            "summary": f"åˆ†æäº†{len(logs)}æ¡æ—¥å¿—ï¼Œå‘ç°{anomaly_count}ä¸ªå¼‚å¸¸",
            "key_findings": ["ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™åˆ†æ", "åŸºäºæ—¥å¿—çº§åˆ«åˆ¤æ–­å¼‚å¸¸"],
            "risk_assessment": {
                "level": "HIGH" if anomaly_count > 0 else "LOW",
                "description": f"å‘ç°{anomaly_count}ä¸ªå¼‚å¸¸æ—¥å¿—" if anomaly_count > 0 else "æ‰€æœ‰æ—¥å¿—æ­£å¸¸"
            },
            "recommendations": ["å»ºè®®å¯ç”¨LLMæ·±åº¦åˆ†æè·å¾—æ›´å‡†ç¡®çš„ç»“æœ"],
            "anomaly_count": anomaly_count,
            "total_count": len(logs)
        }